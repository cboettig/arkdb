% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ark.R
\name{ark}
\alias{ark}
\title{Archive tables from a database as flat files}
\usage{
ark(db_con, dir, streamable_table = streamable_readr_tsv(), lines = 10000L,
  compress = c("bzip2", "gzip", "xz", "none"), tables = list_tables(db_con))
}
\arguments{
\item{db_con}{a database connection}

\item{dir}{a directory where we will write the compressed text files output}

\item{streamable_table}{interface (WIP) for serialising/deserialising in chunks}

\item{lines}{the number of lines to use in each single chunk}

\item{compress}{file compression algorithm. Should be one of "bzip2" (default),
"gzip" (faster write times, a bit less compression), "xz", or "none", for
no compression.}

\item{tables}{a list of tables from the database that should be
archived.  By default, will archive all tables.}
}
\value{
the path to \code{dir} where output files are created (invisibly), for piping.
}
\description{
Archive tables from a database as flat files
}
\details{
\code{ark} will archive tables from a database as (compressed) tsv files.
\code{ark} does this by reading only chunks at a time into memory, allowing it to
process tables that would be too large to read into memory all at once (which
is probably why you are using a database in the first place!)  Compressed
text files will likely take up much less space, making them easier to store and
transfer over networks.  Compressed plain-text files are also more archival
friendly, as they rely on widely available and long-established open source compression
algorithms and plain text, making them less vulnerable to loss by changes in
database technology and formats.
}
\examples{
\donttest{
# setup
library(dplyr)
dir <- tempdir() 
db <- dbplyr::nycflights13_sqlite(tempdir())

## And here we go:
ark(db, dir)


}
}
